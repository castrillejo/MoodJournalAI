# Plan de Fine-Tuning para MoodJournalAI

## âœ… Estado Actual (lo que ya tienes)

### Datos
- **6,124 entradas** etiquetadas en `data/entradas.csv`
- **6 emociones:** joy, sadness, fear, anger, love, surprise
- **Textos en inglÃ©s** (perfecto para RoBERTa)

### Modelo
- **RoBERTa-base descargado:** `model-training/download-model/roberta-base-english/`
- ~500 MB en disco
- 125 millones de parÃ¡metros
- Listo para fine-tuning

### Infraestructura
- PostgreSQL funcionando
- Estructura de carpetas organizada
- Entorno virtual Python configurado

---

## ğŸ§  Fundamentos TeÃ³ricos del Fine-tuning

### Â¿QuÃ© son los Embeddings?

Los **embeddings** son representaciones numÃ©ricas de texto que capturan su significado. RoBERTa convierte cada palabra/frase en un vector de **768 nÃºmeros**.

#### Ejemplo simplificado (4 dimensiones):

```
Texto: "I feel happy today"

Tokens â†’ Embeddings:
"I"      â†’ [0.1,  0.2,  0.1,  0.3]
"feel"   â†’ [0.3,  0.8,  0.2,  0.1]
"happy"  â†’ [0.9, -0.1,  0.7,  0.2]
"today"  â†’ [0.2,  0.3,  0.1,  0.4]

Embedding combinado: [0.38, 0.30, 0.28, 0.25]
```

**Cada dimensiÃ³n captura un aspecto del significado:**
- DimensiÃ³n 0: Â¿Es positivo o negativo?
- DimensiÃ³n 1: Â¿Es emocional?
- DimensiÃ³n 2: Â¿Es activo o pasivo?
- DimensiÃ³n 3: Â¿Es sobre el presente?

### Â¿CÃ³mo funciona el Classifier?

El **classifier head** es una capa que multiplica el embedding por pesos aprendidos:

```python
Embedding:      [0.38, 0.30, 0.28, 0.25]

Pesos para JOY:      [+2.0, +1.5, +1.0, +0.5]
Pesos para SADNESS:  [-2.0, +1.5, -0.5, +0.5]
...

Score JOY = (0.38 Ã— 2.0) + (0.30 Ã— 1.5) + (0.28 Ã— 1.0) + (0.25 Ã— 0.5)
          = 0.76 + 0.45 + 0.28 + 0.125
          = 1.615 âœ… GANADOR

Score SADNESS = (0.38 Ã— -2.0) + (0.30 Ã— 1.5) + (0.28 Ã— -0.5) + (0.25 Ã— 0.5)
              = -0.76 + 0.45 - 0.14 + 0.125
              = -0.325

PredicciÃ³n: JOY (82% de confianza)
```

### Â¿QuÃ© cambia durante el Fine-tuning?

#### ANTES del fine-tuning:
- **Embeddings:** Optimizados para inglÃ©s general (Wikipedia, libros)
- **Classifier:** No existe o tiene pesos aleatorios
- **Resultado:** No puede clasificar emociones

#### DURANTE el fine-tuning (con tus 6,124 entradas):
1. El modelo lee "I feel happy" â†’ JOY
2. Genera embedding: `[0.23, -0.45, 0.67, ...]`
3. Classifier predice: JOY (25%) â† Baja confianza
4. **Ajusta pesos:** "Cuando veo 'happy', aumentar dimensiÃ³n X, reducir dimensiÃ³n Y"
5. Repite 6,124 veces Ã— 3 epochs = 18,372 ajustes

#### DESPUÃ‰S del fine-tuning:
- **Embeddings:** Optimizados para emociones en diarios
- **Classifier:** Pesos entrenados para 6 emociones especÃ­ficas
- **Resultado:** Predice JOY (94% de confianza) âœ…

---

## ğŸš€ Plan de AcciÃ³n (4 Fases)

### Fase 1: Preprocesamiento de Datos (1 dÃ­a)

**Objetivo:** Convertir `entradas.csv` en datasets train/val/test

#### Tareas:
1. âœ… Crear script `prepare_dataset.py`
2. âœ… Cargar `entradas.csv` (6,124 entradas)
3. âœ… Limpiar textos (remover NaN, textos vacÃ­os)
4. âœ… Mapear emociones a nÃºmeros:
   ```python
   emotion_map = {
       'joy': 0,
       'sadness': 1,
       'fear': 2,
       'anger': 3,
       'love': 4,
       'surprise': 5
   }
   ```
5. âœ… Dividir: 80% train / 10% val / 10% test
6. âœ… Guardar CSVs en `model-training/data/`

#### Output esperado:
```
model-training/data/
â”œâ”€â”€ train.csv      (~4,900 entradas)
â”œâ”€â”€ val.csv        (~610 entradas)
â””â”€â”€ test.csv       (~614 entradas)
```

#### Script bÃ¡sico:
```python
import pandas as pd
from sklearn.model_selection import train_test_split

# Cargar datos
df = pd.read_csv("../../data/entradas.csv")

# Seleccionar columnas
df = df[['texto_diario', 'emocion_principal']].dropna()

# Mapear emociones
emotion_map = {'joy': 0, 'sadness': 1, 'fear': 2, 
               'anger': 3, 'love': 4, 'surprise': 5}
df['label'] = df['emocion_principal'].map(emotion_map)

# Dividir
train_df, temp_df = train_test_split(df, test_size=0.2, 
                                     stratify=df['label'], 
                                     random_state=42)
val_df, test_df = train_test_split(temp_df, test_size=0.5, 
                                   stratify=temp_df['label'], 
                                   random_state=42)

# Guardar
train_df.to_csv("data/train.csv", index=False)
val_df.to_csv("data/val.csv", index=False)
test_df.to_csv("data/test.csv", index=False)
```

---

### Fase 2: ConfiguraciÃ³n del Fine-tuning (1 dÃ­a)

**Objetivo:** Configurar el entrenamiento de RoBERTa

#### Tareas:
1. âœ… Crear script `train.py`
2. âœ… Cargar RoBERTa-base desde local
3. âœ… AÃ±adir classifier head (6 clases)
4. âœ… Configurar hiperparÃ¡metros
5. âœ… Configurar logging (TensorBoard)
6. âœ… Configurar guardado de checkpoints

#### Script de entrenamiento:
```python
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer
)
from datasets import load_dataset

# 1. Cargar tokenizer y modelo
tokenizer = AutoTokenizer.from_pretrained(
    "../download-model/roberta-base-english"
)
model = AutoModelForSequenceClassification.from_pretrained(
    "../download-model/roberta-base-english/base",
    num_labels=6,
    id2label={0: 'joy', 1: 'sadness', 2: 'fear', 
              3: 'anger', 4: 'love', 5: 'surprise'},
    label2id={'joy': 0, 'sadness': 1, 'fear': 2, 
              'anger': 3, 'love': 4, 'surprise': 5}
)

# 2. Cargar datos
dataset = load_dataset('csv', data_files={
    'train': 'data/train.csv',
    'validation': 'data/val.csv'
})

# 3. Tokenizar
def tokenize_function(examples):
    return tokenizer(examples['texto_diario'], 
                    truncation=True, 
                    padding='max_length', 
                    max_length=128)

tokenized_datasets = dataset.map(tokenize_function, batched=True)

# 4. Configurar entrenamiento
training_args = TrainingArguments(
    output_dir="./models/roberta-sentiment-6emotions",
    num_train_epochs=3,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=32,
    learning_rate=2e-5,
    weight_decay=0.01,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="f1",
    logging_dir="./logs",
    logging_steps=50,
)

# 5. Entrenar
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets['train'],
    eval_dataset=tokenized_datasets['validation'],
)

trainer.train()

# 6. Guardar modelo final
model.save_pretrained("./models/final")
tokenizer.save_pretrained("./models/final")
```

---

### Fase 3: Entrenamiento (2-4 horas con GPU)

**Objetivo:** Entrenar RoBERTa para clasificar 6 emociones

#### Hardware recomendado:
- **GPU (recomendado):** Google Colab (gratis), Kaggle, o local
  - Tiempo: 2-4 horas
- **CPU (lento):** Posible pero tardarÃ¡ 1-2 dÃ­as

#### Proceso:
```bash
# Activar entorno virtual
.\.venv\Scripts\Activate

# Ir a la carpeta de scripts
cd model-training/scripts

# Ejecutar entrenamiento
python train.py
```

#### Output durante entrenamiento:
```
Epoch 1/3
  Step 100/306: Loss=1.456, Learning Rate=2e-5
  Step 200/306: Loss=1.123, Learning Rate=2e-5
  Step 306/306: Loss=0.892
  Evaluation: F1=0.65, Accuracy=0.63

Epoch 2/3
  Step 100/306: Loss=0.745, Learning Rate=2e-5
  Step 200/306: Loss=0.623, Learning Rate=2e-5
  Step 306/306: Loss=0.521
  Evaluation: F1=0.74, Accuracy=0.72

Epoch 3/3
  Step 100/306: Loss=0.456, Learning Rate=2e-5
  Step 200/306: Loss=0.389, Learning Rate=2e-5
  Step 306/306: Loss=0.312
  Evaluation: F1=0.79, Accuracy=0.77

Training complete! Best model saved to ./models/final
```

#### Archivos generados:
```
model-training/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ roberta-sentiment-6emotions/  # Checkpoints
â”‚   â”‚   â”œâ”€â”€ checkpoint-306/
â”‚   â”‚   â”œâ”€â”€ checkpoint-612/
â”‚   â”‚   â””â”€â”€ checkpoint-918/
â”‚   â”‚
â”‚   â””â”€â”€ final/                        # Mejor modelo
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ model.safetensors (~500 MB)
â”‚       â”œâ”€â”€ vocab.json
â”‚       â””â”€â”€ merges.txt
â”‚
â””â”€â”€ logs/
    â””â”€â”€ events.out.tfevents...        # Para TensorBoard
```

---

### Fase 4: EvaluaciÃ³n (1 hora)

**Objetivo:** Verificar calidad del modelo en datos no vistos

#### Script de evaluaciÃ³n:
```python
from transformers import pipeline
from sklearn.metrics import classification_report, confusion_matrix
import pandas as pd

# 1. Cargar modelo entrenado
classifier = pipeline(
    "text-classification",
    model="./models/final",
    tokenizer="./models/final"
)

# 2. Cargar test set
test_df = pd.read_csv("data/test.csv")

# 3. Hacer predicciones
predictions = []
for text in test_df['texto_diario']:
    pred = classifier(text)[0]
    predictions.append(pred['label'])

# 4. MÃ©tricas
print(classification_report(
    test_df['emocion_principal'], 
    predictions
))

# 5. Matriz de confusiÃ³n
cm = confusion_matrix(
    test_df['emocion_principal'], 
    predictions,
    labels=['joy', 'sadness', 'fear', 'anger', 'love', 'surprise']
)
print(cm)
```

#### Resultados esperados:
```
              precision    recall  f1-score   support

         joy       0.85      0.82      0.83       120
     sadness       0.78      0.81      0.79       115
        fear       0.72      0.68      0.70        95
       anger       0.75      0.79      0.77       110
        love       0.81      0.84      0.82       100
    surprise       0.69      0.65      0.67        74

    accuracy                           0.77       614
   macro avg       0.77      0.77      0.76       614
weighted avg       0.77      0.77      0.77       614
```

**Meta de Ã©xito:** F1-Score > 0.70 (70% de precisiÃ³n)

---

## ğŸ“Š AnÃ¡lisis de Datos Recomendado

Antes del fine-tuning, es importante analizar la distribuciÃ³n de emociones:

```python
import pandas as pd

df = pd.read_csv("../data/entradas.csv")
print(df['emocion_principal'].value_counts())
```

**DistribuciÃ³n ideal:** 800-1500 ejemplos por emociÃ³n

**Si hay desbalance:**
- Usar `class_weight` en el Trainer
- Data augmentation (parafrasear textos)
- Oversampling de clases minoritarias

---

## âš™ï¸ HiperparÃ¡metros Explicados

```python
TrainingArguments(
    # Ã‰pocas: cuÃ¡ntas veces el modelo ve todos los datos
    num_train_epochs=3,          # 3 pasadas completas
    
    # Batch sizes: cuÃ¡ntos ejemplos procesa a la vez
    per_device_train_batch_size=16,   # GPU: 16, CPU: 8
    per_device_eval_batch_size=32,    # MÃ¡s grande en eval
    
    # Learning rate: cuÃ¡nto ajusta los pesos en cada paso
    learning_rate=2e-5,          # 0.00002 (comÃºn para BERT/RoBERTa)
    
    # Weight decay: regularizaciÃ³n para evitar overfitting
    weight_decay=0.01,
    
    # EvaluaciÃ³n: cuÃ¡ndo evaluar el modelo
    evaluation_strategy="epoch",  # Al final de cada Ã©poca
    
    # Guardado: cuÃ¡ndo guardar checkpoints
    save_strategy="epoch",
    
    # Mejor modelo: cargar el mejor al final
    load_best_model_at_end=True,
    metric_for_best_model="f1",  # Usar F1-Score
)
```

---

## ğŸ¯ Estructura de Archivos Final

```
MoodJournalAI/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ entradas.csv              # Datos originales (6,124)
â”‚
â””â”€â”€ model-training/
    â”œâ”€â”€ data/                     # Datos procesados
    â”‚   â”œâ”€â”€ train.csv             # 4,900 entradas
    â”‚   â”œâ”€â”€ val.csv               # 610 entradas
    â”‚   â””â”€â”€ test.csv              # 614 entradas
    â”‚
    â”œâ”€â”€ scripts/                  # Scripts de trabajo
    â”‚   â”œâ”€â”€ prepare_dataset.py    # Paso 1
    â”‚   â”œâ”€â”€ train.py              # Paso 2 y 3
    â”‚   â”œâ”€â”€ evaluate.py           # Paso 4
    â”‚   â””â”€â”€ predict.py            # Uso del modelo
    â”‚
    â”œâ”€â”€ models/                   # Modelos entrenados
    â”‚   â”œâ”€â”€ roberta-sentiment-6emotions/
    â”‚   â””â”€â”€ final/                # Mejor modelo
    â”‚       â”œâ”€â”€ config.json
    â”‚       â””â”€â”€ model.safetensors
    â”‚
    â”œâ”€â”€ logs/                     # Logs de entrenamiento
    â”‚   â””â”€â”€ tensorboard/
    â”‚
    â””â”€â”€ download-model/           # Modelo base original
        â””â”€â”€ roberta-base-english/
```

---

## ğŸš¨ Troubleshooting

### Error: Out of Memory (GPU)
```python
# SoluciÃ³n: reducir batch size
per_device_train_batch_size=8  # en vez de 16
```

### Error: Training muy lento (CPU)
```python
# SoluciÃ³n: usar Google Colab gratis con GPU
# O reducir datos de entrenamiento para pruebas
train_df_sample = train_df.sample(1000)
```

### Error: Overfitting (train accuracy alta, val accuracy baja)
```python
# SoluciÃ³n: aÃ±adir regularizaciÃ³n
weight_decay=0.1  # aumentar de 0.01
# O reducir Ã©pocas
num_train_epochs=2
```

---

## ğŸ“ˆ PrÃ³ximos Pasos DespuÃ©s del Fine-tuning

1. **Integrar con backend:** API FastAPI para predicciones
2. **Crear interfaz:** Frontend para probar el modelo
3. **Deployment:** Servir modelo en producciÃ³n
4. **Monitoreo:** Tracking de predicciones y mÃ©tricas

---

## ğŸ“ Recursos Adicionales

- **Hugging Face Transformers:** https://huggingface.co/docs/transformers/
- **RoBERTa paper:** https://arxiv.org/abs/1907.11692
- **Fine-tuning guide:** https://huggingface.co/docs/transformers/training

---

**Ãšltima actualizaciÃ³n:** 2025-12-03  
**Modelo:** RoBERTa-base (inglÃ©s)  
**Dataset:** 6,124 entradas en inglÃ©s  
**Objetivo:** Clasificar 6 emociones (joy, sadness, fear, anger, love, surprise)
