# ğŸ“¥ Descarga de Modelo RoBERTa-base (InglÃ©s)

Esta carpeta contiene el script para descargar el modelo **RoBERTa-base** (inglÃ©s) pre-entrenado desde Hugging Face Hub.

## ğŸ¯ Modelo

- **Nombre:** `roberta-base`
- **Tipo:** RoBERTa base entrenado en inglÃ©s
- **ParÃ¡metros:** ~125 millones
- **Corpus:** BookCorpus, Wikipedia inglÃ©s, CC-News, OpenWebText, STORIES
- **TamaÃ±o descarga:** ~500 MB
- **Arquitectura:** 12 capas, 768 dimensiones, 12 attention heads

## âœ¨ Â¿Por quÃ© RoBERTa en lugar de BERT?

- **Mejor entrenamiento:** MÃ¡s datos, mÃ¡s tiempo, lotes mÃ¡s grandes
- **Sin NSP:** Eliminada la tarea de "Next Sentence Prediction"
- **Dynamic masking:** Patrones de masking cambian en cada Ã©poca
- **Rendimiento:** Supera a BERT original en la mayorÃ­a de benchmarks

## ğŸš€ Uso

### 1. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 2. Ejecutar descarga

```bash
python download_roberta.py
```

El script:
- âœ… Descarga el modelo y tokenizer desde Hugging Face
- âœ… Guarda todo en la carpeta `roberta-base-english/`
- âœ… Verifica que la descarga fue exitosa
- âœ… Muestra informaciÃ³n sobre cÃ³mo usar el modelo

## ğŸ“‚ Estructura despuÃ©s de la descarga

```
download-model/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ download_roberta.py
â””â”€â”€ roberta-base-english/       # â† Creada automÃ¡ticamente
    â”œâ”€â”€ config.json
    â”œâ”€â”€ tokenizer.json
    â”œâ”€â”€ vocab.json
    â”œâ”€â”€ merges.txt
    â””â”€â”€ base/
        â””â”€â”€ pytorch_model.bin   # ~500 MB
```

## ğŸ’¡ PrÃ³ximos pasos

Una vez descargado el modelo, puedes:

1. **Usarlo directamente para inferencia**
2. **Hacer fine-tuning** para anÃ¡lisis de sentimientos con tus 6 emociones
3. **Experimentar** en notebooks

## ğŸ” Verificar la descarga

El script automÃ¡ticamente verifica que el modelo se descargÃ³ correctamente. Si ves el mensaje "âœ… Modelo verificado correctamente", todo estÃ¡ listo.

## ğŸ¯ Para tu proyecto MoodJournalAI

Este modelo es perfecto para:
- Textos en **inglÃ©s** (tus datos en `entradas.csv`)
- Fine-tuning para **6 emociones**: joy, sadness, fear, anger, love, surprise
- Balance entre **rendimiento** y **tamaÃ±o**

## âš ï¸ Notas

- **ConexiÃ³n a internet:** Necesaria solo para la primera descarga
- **Espacio en disco:** ~500 MB libres recomendados
- **Tiempo estimado:** 3-7 minutos (dependiendo de tu conexiÃ³n)
- **Idioma:** Optimizado para **inglÃ©s** (perfecto para tus datos)
